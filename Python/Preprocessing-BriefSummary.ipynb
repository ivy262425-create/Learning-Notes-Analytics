{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83fbf9-4517-41aa-9736-3acdbca1fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check na\n",
    "#data.isna().sum()\n",
    "X = df.drop('target_column', axis=1)\n",
    "y = df['target_column']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b96cb-5583-4df2-8d4c-2b30a32e3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value imputation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# \n",
    "mean_age = df['age'].mean()\n",
    "df['age'].fillna(mean_age, inplace=True)\n",
    "# \n",
    "median_salary = df['salary'].median()\n",
    "df['salary'].fillna(median_salary, inplace=True)\n",
    "#\n",
    "mode_city = df['city'].mode()[0]\n",
    "df['city'].fillna(mode_city, inplace=True)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')#strategy=\"most_frequent\"\n",
    "x = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a249e-9259-4719-bebb-ee025db1ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- For Numerical Columns ---\n",
    "# EN: 1. Create the imputer\n",
    "imputer_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# EN: 2. Learn from and transform the training set\n",
    "X_train['numeric_col'] = imputer_mean.fit_transform(X_train[['numeric_col']])\n",
    "X_test['numeric_col'] = imputer_mean.transform(X_test[['numeric_col']])\n",
    "\n",
    "# --- For Categorical Columns ---\n",
    "imputer_freq = SimpleImputer(strategy='most_frequent')\n",
    "X_train['categorical_col'] = imputer_freq.fit_transform(X_train[['categorical_col']])\n",
    "X_test['categorical_col'] = imputer_freq.transform(X_test[['categorical_col']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03310d-b27e-4b05-bd62-82287ea817fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "#IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]]) # the second feature is double of the first\n",
    "IterativeImputer(random_state=0)\n",
    "imp.transform(X_test)\n",
    "#nearest neighbors\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035f92f-c071-4a32-ad21-1c601531ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)    \n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "poly.fit_transform(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1f499e-24e7-4e69-949d-0cf415d8d536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling Numerical Features:\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['age', 'salary']\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5247781a-4fd9-454f-b713-4de3526f1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc1 = OrdinalEncoder() #ordinal or decisiontree\n",
    "enc2 = OneHotEncoder()\n",
    "x_encoded = enc1.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3795c-aa21-4468-8497-3902710cded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# EN: 1. Create the encoder instance\n",
    "# EN: handle_unknown='ignore' prevents errors if the test set has new categories\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# EN: 2. Learn from and transform the training set\n",
    "encoded_cols_train = encoder.fit_transform(X_train[['city']])\n",
    "\n",
    "# EN: 3. Only transform the test set\n",
    "encoded_cols_test = encoder.transform(X_test[['city']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc31d5-92ff-4ad0-95ec-dcfb6384b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discrete\n",
    "import pandas as pd\n",
    "cbank['age'] = pd.cut(\n",
    "    bank_full['age'],\n",
    "    bins=[18, 30, 45, 60, np.inf],\n",
    "    labels=['Youth', 'Adult', 'Mid', 'Senior'],\n",
    "    right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2967f-6110-487c-8495-2fee9a3354a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr\n",
    "correlation_matrix_new = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix_new, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of New Numerical Features\")\n",
    "plt.show()\n",
    "#save to csv  df.to_csv('D:/train_new.csv')\n",
    "#pairplot\n",
    "import seaborn as sns\n",
    "sns.pairplot(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
